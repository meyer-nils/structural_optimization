{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 01 - Tensors\n",
    "\n",
    "In Chapter 1 of the lecture, we recapitulated tensor notation and tensor analysis. In this exercise, we will learn how to code these operations with torch in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Installation and Python Basics\n",
    "\n",
    "There are many ways to install Python and many editors to write Python code. If you have already a version of Python or Anaconda installed, you can keep that version. However, if you are installing Python for the first time, I recommend the following procedure:\n",
    "\n",
    "### Install a minimal Python\n",
    "- Go to https://github.com/conda-forge/miniforge and download installer of \"Miniforge 3\" for your operating system\n",
    "- Start the installer\n",
    "- Install for \"Just Me\" and add to PATH variable\n",
    "\n",
    "### Install Visual Studio Code as your code editor\n",
    "- Go to https://code.visualstudio.com and download installer of \"Visual Studio Code\" for your operating system \n",
    "- Start the installer\n",
    "- Install using your personal preferences (desktop icon etc.)\n",
    "- Customize to your liking\n",
    "\n",
    "### Install required packages\n",
    "To solve the tasks with code, we will use a package called torch-fem. It is a differentiable finite element solver based on the PyTorch framework. PyTorch is a powerful Python package to operate on tensors. In comparison to NumPy, it stores gradients together with tensors and thus allows automatic differentiation. The package is used widely for machine learning and optimization. \n",
    "\n",
    "For installation it is best to create a new conda environment via\n",
    "```bash\n",
    "    conda create -n \"struct_opt\" python\n",
    "```\n",
    "and activate that environment via\n",
    "```bash\n",
    "    conda activate struct_opt\n",
    "``` \n",
    "to have a fresh new independent virtual Python environment to install the required packages with this course. It is highly recommended to use such an environment to prevent potential conflicts with other Python projects.\n",
    "\n",
    "In the activated environment, you should install the package torch-fem\n",
    "```bash\n",
    "    pip install torch-fem\n",
    "```\n",
    "to install the required packages. After that, you should be able to import the torch package in this Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchfem.utils import plot_contours\n",
    "\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Define the variables $a=2.0$ and $b=3.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Compute the sum $c=a+b$ and print the result using the built-in `print()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Use an f-string to print a formatted statement as \"The sum of a=< a > and b=< b > is < c >.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Here is a function `multiply(x,y)`. Call it with variables $a$ and $b$ and assign the result to a variable $d$. Print $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(x, y):\n",
    "    return x * y\n",
    "\n",
    "\n",
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Write a function that divides two numbers and adds a third number to the result. Test it by computing $e$ with inputs $a$, $b$, $4.0$. Print $e$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) You get a list of integers called `numbers`. Iterate over the items in the list with a `for` loop and print for each item wether it is odd or even. \n",
    "\n",
    "**Hint:** The modulo operator `i%j` returns the remainder of the division $i/j$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [33, 43, 9, 7, 38, 25, 17, 19, 29]\n",
    "\n",
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Implement a function that takes a list as argument and finds the maximum value in that list. It should return the maximum value and the location of the maximum in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here\n",
    "\n",
    "value, position = find_max(numbers)\n",
    "print(f\"Resulting value: {value}, resulting position: {position}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Vectors and vector products in torch\n",
    "\n",
    "Two vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathcal{R}^3$ are given by their components\n",
    "$$\n",
    "x_i = \\begin{pmatrix}2\\\\1\\\\3\\end{pmatrix} \\quad y_i = \\begin{pmatrix}5\\\\0\\\\1\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "a) Define the vectors in torch using `torch.tensor(data)`. The `data` is an array-like object, e.g. a list or tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Compute the inner product (=scalar product, dot product) between those two tensors using `torch.inner(x,y)` and print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Tensors and tensor products in torch\n",
    "\n",
    "Given are the tensors $\\mathbf{n} \\in \\mathcal{R}^{3}$, $\\mathbf{E} \\in \\mathcal{R}^{3 \\times 3}$, and $\\mathbb{C} \\in \\mathcal{R}^{3 \\times 3 \\times 3 \\times 3}$ by their components \n",
    "$$\n",
    "n_i =\n",
    "\\begin{pmatrix}1.0\\\\0.0\\\\0.0\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "\\pmb{\\varepsilon}_{ij} =\n",
    "\\begin{pmatrix}\n",
    "    5.0 & 0.1 & 0.0\\\\\n",
    "    0.1 & 2.0 & 0.0\\\\\n",
    "    0.0 & 0.0 & 1.0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "C_{ijkl} = \\lambda \\delta_{ij} \\delta_{kl} + \\mu \\left(\\delta_{ik}\\delta_{jl} + \\delta_{il}\\delta_{jk}\\right)\n",
    "$$\n",
    "with $\\lambda=1.0$ and $\\mu=2.0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Define the tensors $n$ and $\\pmb{\\varepsilon}$ using `torch.tensor()` and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Define the tensor $\\mathbb{C}$ using `torch.einsum()`. See https://pytorch.org/docs/stable/generated/torch.einsum.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Compute a stress tensor $$\\pmb{\\sigma} = \\mathbb{C} : \\pmb{\\varepsilon}$$ using `torch.tensordot()` and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Compute a traction tensor $$\\mathbf{t} = \\pmb{\\sigma} \\cdot \\mathbf{n}$$ using `torch.matmul()` or its short form `@` and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Compute a strain energy density $$E = \\frac{1}{2}\\pmb{\\sigma} : \\pmb{\\varepsilon}$$ using `torch.tensordot()` and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Gradients in 1D \n",
    "\n",
    "We are given a function $g: \\mathbf{R} \\rightarrow \\mathbf{R}$ defined as \n",
    "\n",
    "$$\n",
    "g(x) = x^2+x+1\n",
    "$$\n",
    "\n",
    "define the function, compute its gradient and plot it on $x \\in [-5, 5]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Define the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use `torch.linspace(start, end, steps, requires_grad=True)` to create a variable $x \\in [-5, 5]$. Setting `requires_grad=True` enables the computation of gradients using automatic differentiation. We treat this powerful feature as a black-box in this lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here\n",
    "\n",
    "# Compute the gradient\n",
    "dgdx = torch.autograd.grad(g(x).sum(), x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Verify that the shown results are correct by hand calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot function and gradient\n",
    "with torch.no_grad():\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].plot(x, g(x), color=\"black\")\n",
    "    ax[0].set_xlabel(\"x\")\n",
    "    ax[0].set_ylabel(\"g(x)\")\n",
    "    ax[0].set_title(\"Function g(x)\")\n",
    "    ax[0].grid()\n",
    "    ax[1].plot(x, dgdx, color=\"deeppink\")\n",
    "    ax[1].set_xlabel(\"x\")\n",
    "    ax[1].set_ylabel(\"dg/dx\")\n",
    "    ax[1].set_title(\"Gradient dg/dx\")\n",
    "    ax[1].grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Gradients in 2D \n",
    "Given is a vectorfield $f: \\mathcal{R}^2 \\rightarrow \\mathcal{R}$ defined as \n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = (\\mathbf{x} - \\tilde{\\mathbf{x}}) \\cdot \\mathbf{Q} \\cdot (\\mathbf{x} - \\tilde{\\mathbf{x}})\n",
    "$$\n",
    "with \n",
    "$$\n",
    "\\mathbf{Q} = \n",
    "\\begin{pmatrix}\n",
    "    2 & 1 \\\\\n",
    "    1 & 1 \n",
    "\\end{pmatrix} \n",
    "\\quad \n",
    "\\text{and}\n",
    "\\quad\n",
    "\\tilde{\\mathbf{x}} = \n",
    "\\begin{pmatrix}\n",
    "    -1\\\\\n",
    "    1 \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Compute the gradient analytically."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing these computations by hand takes a while. Therefore we take a look at how to compute gradients using PyTorch. To do so, we start by defining $\\mathbf{Q}$, $\\tilde{\\mathbf{x}}$ and the function $f(\\mathbf{x})$. \n",
    "\n",
    "b) Implement the function $f(\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to be able to evaluate the function for many values of $\\mathbf{x}$ at the same time. This is equivalent to passing a tensor of the shape $\\mathcal{R}^{... \\times 2}$ with arbitrary dimensions except the last axis. \n",
    "\n",
    "c) Reimplement the function $f(x)$ employing an ellipsis `...` in `torch.einsum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your function is defined correctly, the following cell should plot the function values as a contour plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x grid\n",
    "x0 = torch.linspace(-3, 3, steps=100, requires_grad=True)\n",
    "x1 = torch.linspace(-3, 3, steps=100, requires_grad=True)\n",
    "x_grid = torch.stack(torch.meshgrid(x0, x1, indexing=\"xy\"), dim=2)\n",
    "\n",
    "plot_contours(x_grid, f(x_grid), title=\"f(x)\", figsize=(5, 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `requires_grad=True` argument defines that these specific tensors will be used in gradient computations. They reserve storage for the tensor data as well as the gradients. Now, lets compute the actual gradients with automatic differentiation.\n",
    "\n",
    "d) Check if the gradients are computed correctly by comparing the result with the analytical derivation and your visual understanding of the gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradient\n",
    "dfdx = torch.autograd.grad(f(x_grid).sum(), x_grid)[0]\n",
    "\n",
    "# Reproduce basic plot\n",
    "plot_contours(x_grid, f(x_grid), title=\"f(x)\", figsize=(5, 5))\n",
    "\n",
    "# Plot gradient vectors as arrows on top of previous plot\n",
    "with torch.no_grad():\n",
    "    stride = 5\n",
    "    plt.quiver(\n",
    "        x_grid[::stride, ::stride, 0],\n",
    "        x_grid[::stride, ::stride, 1],\n",
    "        dfdx[::stride, ::stride, 0],\n",
    "        dfdx[::stride, ::stride, 1],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "struct_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
