{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 06 - Shape optimization of trusses\n",
    "\n",
    "Shape optimization means that given a fixed topology of a truss, we want optimize its stiffness by modifying some node positions. In this particular example, we investigate the optimal shape of a railway bridge like in the photograph here:\n",
    "\n",
    "![Bridge](https://meyer-nils.github.io/structural_optimization/figures/bridge.jpeg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchfem import Truss\n",
    "from torchfem.materials import IsotropicElasticity1D\n",
    "\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's start by defining the base truss topology of the bridge without considering the exact shape for now. We create a simple rectangular bridge that has all the bars seen in the photo. The truss is fixed at the bottom left side and simply supported at the bottom right side. The load is distributed along the bottom edge of the bridge, which represents the train track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions\n",
    "A = 17\n",
    "B = 2\n",
    "\n",
    "# Nodes\n",
    "n1 = torch.linspace(0.0, 5.0, A)\n",
    "n2 = torch.linspace(0.0, 0.5, B)\n",
    "n1, n2 = torch.stack(torch.meshgrid(n1, n2, indexing=\"xy\"))\n",
    "nodes = torch.stack([n1.ravel(), n2.ravel()], dim=1)\n",
    "\n",
    "# Elements\n",
    "connections = []\n",
    "for i in range(A - 1):\n",
    "    for j in range(B):\n",
    "        connections.append([i + j * A, i + 1 + j * A])\n",
    "for i in range(A):\n",
    "    for j in range(B - 1):\n",
    "        connections.append([i + j * A, i + A + j * A])\n",
    "for i in range(A - 1):\n",
    "    for j in range(B - 1):\n",
    "        if i >= (A - 1) / 2:\n",
    "            connections.append([i + j * A, i + 1 + A + j * A])\n",
    "        else:\n",
    "            connections.append([i + 1 + j * A, i + A + j * A])\n",
    "elements = torch.tensor(connections)\n",
    "\n",
    "# Create material\n",
    "material = IsotropicElasticity1D(E=500.0)\n",
    "\n",
    "# Create Truss\n",
    "bridge = Truss(nodes.clone(), elements, material)\n",
    "\n",
    "# Forces at bottom edge\n",
    "bridge.forces[1 : A - 1, 1] = -0.1\n",
    "\n",
    "# Constraints by the supports\n",
    "bridge.constraints[0, 0] = True\n",
    "bridge.constraints[0, 1] = True\n",
    "bridge.constraints[A - 1, 1] = True\n",
    "\n",
    "# Plot\n",
    "bridge.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce some helper functions from the last exercises. These are just copies of functions you are already familiar with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lengths(truss):\n",
    "    start_nodes = truss.nodes[truss.elements[:, 0]]\n",
    "    end_nodes = truss.nodes[truss.elements[:, 1]]\n",
    "    dx = end_nodes - start_nodes\n",
    "    return torch.linalg.norm(dx, dim=-1)\n",
    "\n",
    "\n",
    "def box_constrained_decent(\n",
    "    func, x_init, x_lower=None, x_upper=None, eta=0.01, max_iter=100, tol=1e-10\n",
    "):\n",
    "    x = x_init.clone().requires_grad_()\n",
    "    for _ in range(max_iter):\n",
    "        x_old = x.clone()\n",
    "        grad = torch.autograd.grad(func(x).sum(), x)[0]\n",
    "        x = x - eta * grad\n",
    "        x = torch.clamp(x, x_lower, x_upper)\n",
    "        if torch.norm(x - x_old) < tol:\n",
    "            return x\n",
    "    return x\n",
    "\n",
    "\n",
    "def MMA(func, x_k, L_k, U_k):\n",
    "    x_lin = x_k.clone().requires_grad_()\n",
    "    grads = torch.autograd.grad(func(x_lin), x_lin)[0]\n",
    "    pg = grads >= 0.0\n",
    "    ng = grads < 0.0\n",
    "    f_k = func(x_k)\n",
    "\n",
    "    def approximation(x):\n",
    "        p = torch.zeros_like(grads)\n",
    "        p[pg] = (U_k[pg] - x_k[pg]) ** 2 * grads[pg]\n",
    "        q = torch.zeros_like(grads)\n",
    "        q[ng] = -((x_k[ng] - L_k[ng]) ** 2) * grads[ng]\n",
    "        return (\n",
    "            f_k\n",
    "            - torch.sum(p / (U_k - x_k) + q / (x_k - L_k))\n",
    "            + torch.sum(p / (U_k - x) + q / (x - L_k))\n",
    "        )\n",
    "\n",
    "    return approximation, grads"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Preparation of design variables\n",
    "\n",
    "We want to restrict the shape optimization problem to the vertical displacement of the top nodes. Other nodes should not be modified - the train track should remain a flat line.\n",
    "\n",
    "a) Create a boolean tensor `mask` of the same shape as `nodes`. It should be `True` for the vertical degrees of freedom of the top nodes and `False` for every other degree of freedom. Essentially it should mask out those nodal degrees of freedom which should be optimized. \n",
    "\n",
    "*Hints:* Take a look at how the boolean `constraints` tensor is created in a cell above. Take a look at the plot of the bridge to see which node numbers are the top nodes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "b) Create initial values `x_0` of the masked top node positions. Set limits to the deformation (`x_min`, `x_max`) such that nodes can move down by 0.4 and up by 0.5 units.\n",
    "\n",
    "*Hints:* Use the `mask` tensor to extract the top node positions and use `ravel()`to flatten the tensor to get a vector of our design variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Compute the current volume of the truss `V0`. We will use this as a constraint in the optimization problem such that the optimized solution does not exceed this initial volume.\n",
    "\n",
    "*Hint:* The current volume is the inner product of the current bar lengths and the cross-sectional `areas` of the bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the solution here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Optimization\n",
    "\n",
    "In this task, we will optimize the shape of the truss by minimizing the compliance of the bridge by adjusting the top nodes while keeping the volume constant: \n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{x}} \\quad C(\\mathbf{x}) = \\mathbf{f} \\cdot \\mathbf{u}(\\mathbf{x}) \\\\\n",
    "\\text{s.t.} \\quad \\mathbf{a} \\cdot \\mathbf{l}(\\mathbf{x}) - V_0 \\le 0\\\\\n",
    "\\quad \\quad x \\in [\\mathbf{x}^{-}, \\mathbf{x}^{+}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Complete the objective function f(x). \n",
    "\n",
    "*Hint:* Replace `bridge.nodes[mask]` with the design variables `x` to update the nodal positions of the top nodes. Use `truss.solve()` to compute the displacements and forces of the updated truss. Use `ravel()` to flatten the tensors and compute the compliance as the inner product of the forces and displacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    # Update the masked nodes\n",
    "\n",
    "    # Solve truss with updated nodes\n",
    "\n",
    "    # Return compliance\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Complete the constraint function g(x).\n",
    "\n",
    "*Hint:* Replace `bridge.nodes[mask]` with the design variables `x` to update the nodal positions of the top nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    # Update nodes\n",
    "\n",
    "    # Return constraint function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Implement the updates of upper and lower asymptotes as in Exercise 04. \n",
    "\n",
    "d) Implement the lower and upper move limits called `x_min_k` and `x_max_k`.\n",
    "\n",
    "e) Compute the approximated functions `f_tilde` and `g_tilde`. \n",
    "\n",
    "*Hints:* The MMA function returns the approximated functions `f_tilde` as well as the gradients of the original functions. You can assign them as follows: `f_tilde, f_Grad = MMA(...)`.\n",
    "\n",
    "f) Implement the approximated Lagrangian $L = \\tilde{f}(\\mathbf{x}) + \\mu \\tilde{g}(\\mathbf{x}) $\n",
    "\n",
    "g) Implement the analytical solution of `x_star(mu)`. \n",
    "\n",
    "*Hints:* This is similar to the analytical solutions in Exercise 04. Start by defining an empty stationary point `x_hat` filled with zeros of the same shape as `f_grad`. Then, define the conditions for the four cases of the analytical solution and fill the `x_hat` tensor accordingly by setting `x_hat[cond1] = solution1` etc. Finally, clamp the results with the move limits. \n",
    "\n",
    "h) Implement the negative dual function $-\\underbar{L}(\\mu) = -L(x^*(\\mu), \\mu)$\n",
    "\n",
    "i) Solve for the maximum of the dual function with `box_constrained_decent(...)`.\n",
    "\n",
    "j) Append the solution to the list of solutions `x` = [$\\mathbf{x}^0, \\mathbf{x}^1, \\mathbf{x}^2, ...$] containing the iteration steps of the optimization procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0.7\n",
    "\n",
    "# Set up lists for L, U, x\n",
    "L = []\n",
    "U = []\n",
    "x = [x_0]\n",
    "\n",
    "# Define the initial value, lower bound, and upper bound of \"mu\"\n",
    "mu_0 = torch.tensor([0.01])\n",
    "mu_lower = torch.tensor([1e-10])\n",
    "mu_upper = None\n",
    "\n",
    "for k in range(50):\n",
    "    # Update asymptotes with heuristic procedure (see Exercise 04)\n",
    "\n",
    "    # Compute lower and upper move limit in this step\n",
    "\n",
    "    # Compute the current approximation function and save gradients\n",
    "\n",
    "    # Define the Lagrangian\n",
    "    def Lagrangian(x, mu):\n",
    "        pass\n",
    "\n",
    "    # Define x_star by minimizing the Lagrangian w. r. t. x analytically\n",
    "    def x_star(mu):\n",
    "        pass\n",
    "\n",
    "    # Define (-1 times) the dual function\n",
    "    def dual_function(mu):\n",
    "        pass\n",
    "\n",
    "    # Compute the maximum of the dual function\n",
    "\n",
    "    # Compute current optimal point with dual solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the development of design variables\n",
    "plt.plot(torch.stack(x).detach())\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Values $x_i$\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the optimized bridge\n",
    "bridge.plot(node_labels=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "struct_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
